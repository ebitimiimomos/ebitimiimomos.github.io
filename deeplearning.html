<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <!-- Google Fots -->
     <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" rel="stylesheet">
      <!-- Remixicon Icon -->
      <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
      <!-- Remixicon Icon -->
      <!-- Bootstrap CSS -->
      <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
      <link href="https://unpkg.com/aos@2.3.1/dist/aos.css" rel="stylesheet">
      <!-- Main CSS -->
      <link href="assets/css/main.css" rel="stylesheet">


    <title>Deep Learning</title>
  </head>
  <body>
   
    <!-- header -->
    <header class="ds-header" id="site-header">
        <div class="container">
            <div class="ds-header-inner">
              <!-- logo -->
              <a href="index.html" class="ds-logo">
                <span>E</span>Ebitimi Imomos
              </a>
              <div class="text-center">
                <a href="index.html#ds-work-section" class="ds-button ds-arrow-button"><i class="ri-arrow-left-s-line"></i> BAck</a>
              </div>
              <!-- logo -->
              <!-- social -->
              <ul class="ds-social">
                <li><a href="https://github.com/ebitimiimomos" target="_blank"><i class="ri-github-fill"></i></a></li>
                <li><a href="https://leetcode.com/Ebitimi/" target="_blank"><i class="iconify" data-icon="simple-icons:leetcode"></i></a></li>
                <li><a href="https://www.linkedin.com/in/ebitimi-imomotebegha-5a06b019a/" target="_blank"><i class="ri-linkedin-fill"></i></a></li>
              </ul>
              <!-- social -->
            </div>
        </div>
    </header>
    <!-- header -->
   
   <main class="ds-main-section">
     <div class="container">
        <div class="ds-work-details-section">

            <div class="row justify-content-center">
              <div class="col-12 col-sm-12 col-md-10 col-lg-10 col-xl-10 col-xxl-10">
                  <header class="ds-work-det-hed">
                      <h1 class="ds-work-det-title">Implement a deep reinforcement learning agent</h1>
                      <span class="ds-work-det-dep">Python + Ms Excel + Ms Word</span>
                  </header>
                  <figure><img src="assets/images/deeplearning1.jpg"></figure>
                  <div class="ds-button-sec text-center" id="ds-button-sec">
                    <a href="https://1drv.ms/u/s!AiMftykPpguWgkI8-BMpdm4Fgikd?e=RgSUL4" target="_blank" rel="noopener noreferrer" class="ds-button" id="ds-button">View Code</a>
                 </div>
                  <div class="ds-work-content-sec">
                      <div class="row justify-content-center">
                          <div >

<h2>Project Overview</h2>
<p>In this project, I aimed to solve a deep reinforcement learning problem using OpenAI Gym. The objective was to train a Proximal Policy Optimization (PPO) agent with a 'CnnPolicy' to navigate a racing car through a track without crashing. The CnnPolicy with PPO was chosen because it provides a robust algorithm that can capture spatial and temporal relationships in the game environment.</p>
<h2>Training the PPO Agent</h2>
<p>The PPO agent was trained using the Stable-Baselines library with specific hyperparameters. The training performance showed that the agent performed reasonably well, simulating an average of 16 frames per second over 2,500,608 timesteps.</p>
<p>The agent's approx_kl value indicated that the divergence between the current policy and the previous policy was relatively small. However, a significant fraction of clipped samples during training suggested that further hyperparameter optimization might be needed to improve performance.</p>
<h2>Evaluation Phase</h2>
<p>In the evaluation phase, the PPO agent achieved an average reward of -93.35 over 10 evaluation episodes. A negative reward indicates that the agent's performance was worse than the default behavior, and the low standard deviation suggested consistent performance across episodes.</p>
<h2>Exploration and Exploitation</h2>
<p>Exploration and exploitation are crucial concepts in deep reinforcement learning. Exploration involves trying new actions to learn about the environment and discover better policies, while exploitation focuses on selecting the best actions based on the current knowledge to maximize performance. Various techniques, such as epsilon-greedy strategies, deep Q networks, and PPO, can help strike a balance between exploration and exploitation and lead to optimal performance in different tasks.</p>
                          </div>
                      </div>
					  
                  </div>
                 
              </div>
            </div>
        </div>
     </div>
   </main>

   <!--  footer -->
   <footer class="ds-footer text-center" id="ds-footer">
    <div class="container">
       <section>
         <span>Contact</span>
         <h4>Ready to talk?</h4>
         <p>Feel free to contact me</p>
         <a href="mailto:ebitimiimomos@outlook.com" class="ds-button">Send Me a Message!</a>
         
                       <ul class="ds-social">
               <li><a href="https://github.com/ebitimiimomos" target="_blank"><i class="ri-github-fill"></i></a></li>
               <li><a href="https://leetcode.com/Ebitimi/" target="_blank"><i class="iconify" data-icon="simple-icons:leetcode"></i></a></li>
               <li><a href="https://www.linkedin.com/in/ebitimi-imomotebegha-5a06b019a/" target="_blank"><i class="ri-linkedin-fill"></i></a></li>
             </ul>
       </section>
       <span class="ds-copyright">Â© 2023 Ebitimi Imomotebegha.</span>
    </div>
    
    
    
  </footer>
  
  


   <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
   <!-- Option 1: Bootstrap Bundle with Popper -->
   <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
   <script src="https://code.iconify.design/3/3.1.0/iconify.min.js"></script>
   <!-- Option 2: Separate Popper and Bootstrap JS -->
   <!--
   <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js" integrity="sha384-IQsoLXl5PILFhosVNubq5LC7Qb9DXgDA9i+tQ8Zj3iwWAwPtgFTxbJ8NT4GN1R8p" crossorigin="anonymous"></script>
   <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.min.js" integrity="sha384-cVKIPhGWiC2Al4u+LWgxfKTRIcfu0JTxR+EQDz/bgldoEyl4H0zUF0QKbrJ0EcQF" crossorigin="anonymous"></script>
   -->
   <script src="assets/js/main.js"></script>
 </body>
</html>